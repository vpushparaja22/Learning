reduce_file <- data.frame(reduce_file)
reduce_file <- cbind(ticker_dates, reduce_file)
l <- ls()
l <- l[l!="reduce_file"]
rm(list=l)
rm(l)
reduce_list_modified <- NULL
unique_tickers <- unique(reduce_file$ticker)
for(u in unique_tickers){
temp <- subset(reduce_file,ticker==u)
if(dim(temp)[1]==20){
reduce_list_modified <- rbind(reduce_list_modified,temp)
}
temp<-NULL
}
factors <- c('calendardate','revenue','cor','rnd','ebit','netinc','epsdil','ncfo','ncfi','capex',
'ncfdiv','intangibles','debt','de','pe','pb','fcfps','assets','netmargin','marketcap','dps','ln_returns')
reduce_file_original <- reduce_file
reduce_file <- reduce_list_modified
reduce_list_modified <- NULL
unique_dates <- unique(reduce_file$calendardate)
unique_dates_train <- unique_dates[1:15]
unique_dates_test <- unique_dates[16:20]
reduce_file_data <- vector()
for(i in factors){
reduce_file_data <- cbind(reduce_file_data,reduce_file[,i])
}
reduce_file_data <- data.frame(reduce_file_data)
reduce_file_data <- cbind(reduce_file[,'ticker'],reduce_file_data)
colnames(reduce_file_data) <- c('ticker',factors)
coefficients_dates <- vector()
for(j in unique_dates_train){
temp <- subset(reduce_file_data,calendardate==j)
temp[c('calendardate','ticker')] <- list(NULL)
model <- lm(ln_returns ~ . , temp)
browser()
coefficients_dates <- rbind(coefficients_dates,model$coefficients)
temp <- NULL
model <- NULL
}
coefficients_dates <- cbind(unique_dates_train,coefficients_dates)
unique_dates_train_new <- c(20111231, 20130331, 20140331)
tickers <- read.csv("C:/Users/vino2/Google Drive/Semester 3/640 - Predictive/Project/companylist.csv",header = TRUE)
t_tickers <- intersect(tickers$Symbol,reduce_file$ticker)
reduce_file_tickers_data <- vector()
for(i in t_tickers){
reduce_file_tickers_data <- rbind(reduce_file_tickers_data,reduce_file_data[reduce_file_data$ticker==i,])
}
n_factors <- c('revenue','cor','rnd','ebit','netinc','epsdil','ncfo','ncfi','capex','ncfdiv',
'intangibles','debt','de','pe','pb','fcfps','assets','netmargin','marketcap','dps')
n_factors <- paste(n_factors, collapse = "+")
formula_ <- as.formula(paste("ln_returns~", n_factors, collapse = "+"))
coefficients_tickers_train[] <- vector()
temp <- NULL
temp <- subset(reduce_file_tickers_data,calendardate==20140331)
temp[c('calendardate','ticker')] <- list(NULL)
model <- neuralnet(formula = formula_, temp, hidden = 14)
plot(model)
temp <- NULL
model <- NULL
coefficients_tickers <- vector()
temp <- NULL
for(j in unique_dates){
temp <- subset(reduce_file_tickers_data,calendardate==j)
temp[c('calendardate','ticker')] <- list(NULL)
model <- lm(ln_returns ~ . , temp)
#print(model$coefficients)
coefficients_tickers <- rbind(coefficients_tickers,model$coefficients)
temp <- NULL
model <- NULL
}
pred <- compute(model, temp)
temp <- subset(reduce_file_tickers_data,calendardate==20140331)
temp[c('calendardate','ticker')] <- list(NULL)
pred <- compute(model, temp)
View(temp)
all(is.na(temp))
temp1$ln_returns <- NULL
temp1 <- temp
temp1$ln_returns <- NULL
View(temp1)
pred <- compute(model, temp[,1:20])
pred <- compute(model, temp1)
pred
model <- neuralnet(formula = formula_, temp, hidden = c(9,5))
plot(model)
layers <- c(4, c(9,5), c(5,9), c(7,7))
i = 0
for(j in layers){
model[i] <- neuralnet(formula = formula_, temp, hidden = j)
i <- i + 1
}
model[1]
model[2]
model[3]
model[4]
layers
layers <- list(4, c(9,5), c(5,9), c(7,7))
layers
for(k in layers){
model[j] <- neuralnet(formula = formula_, temp, hidden = k)
}
range(0,3)
xrange(0,3)
[0:3]
c(0,3)
range(0:3)
range(0,3)
c(0:3)
layers <- list(4, c(9,5), c(5,9), c(7,7))
length(layers)
1:length(layers)
layers <- list(4, c(9,5), c(5,9))
for(j in 1:length(layers)){
for(k in layers){
model[j] <- neuralnet(formula = formula_, temp, hidden = k)
}
}
layers <- list(4, c(9,5), c(5,9))
for(j in layers){
for(k in 1:length(layers)){
model[k] <- neuralnet(formula = formula_, temp, hidden = j)
}
}
model[1]
library(neuralnet)
library(MASS)
View(temp)
formula_
model <- NULL
layers[1]
layers[2]
layers[[1]]
layers[[2]]
layers[[3]]
for(j in layers){}
for(j in layers){ }
for(j in layers){ print(j) }
for(j in layers){ print(j) }
layers <- list('4', 'c(9,5)', 'c(5,9)')
layers <- list('4', 'c(9,5)', 'c(5,9)')
for(j in layers){ print(j) }
for(j in layers){ noquote(j) }
for(j in layers){ noquote(j) }
for(j in layers){ noquote(j) }
j
for(j in layers){
noquote(j)
print(j)
}
library(arules)  # association rules
library(arulesViz)  # data visualization of association rules
library(RColorBrewer)  # color palettes for plots
data(Groceries)  # grocery transactions object from arules package
groceries <- aggregate(Groceries, itemInfo(Groceries)[["level2"]])
print(dim(groceries)[1])  # 9835 market baskets for shopping trips
print(dim(groceries)[2])  # 55 final store items (categories)
first.rules <- apriori(groceries,
parameter = list(support = 0.001, confidence = 0.05))
second.rules <- apriori(groceries,
parameter = list(support = 0.025, confidence = 0.05))
vegie.rules <- subset(second.rules, subset = rhs %pin% "vegetables")
inspect(vegie.rules)  # 41 rules
top.vegie.rules <- head(sort(vegie.rules, decreasing = TRUE, by = "lift"), 10)
inspect(top.vegie.rules)
diary.rules <- subset(second.rules, subset = rhs %pin% "bread")
inspect(diary.rules)  # 41 rules
top.diary.rules <- head(sort(diary.rules, decreasing = TRUE, by = "confidence"), 10)
inspect(top.diary.rules)
milk.rules <- subset(second.rules, subset = rhs %pin% "milk")
inspect(diary.rules)  # 41 rules
View(Groceries)
print(dim(Groceries))
first.rules <- apriori(groceries,
parameter = list(support = 0.001, confidence = 0.8))
print(summary(first.rules))  # yields 69,921 rules... too many
second.rules <- apriori(groceries,
parameter = list(support = 0.025, confidence = 0.8))
vegie.rules <- subset(second.rules, subset = rhs %pin% "vegetables")
inspect(vegie.rules)  # 41 rules
second.rules <- apriori(groceries,
parameter = list(support = 0.001, confidence = 0.8))
vegie.rules <- subset(second.rules, subset = rhs %pin% "vegetables")
inspect(vegie.rules)  # 41 rules
milk.rules <- subset(second.rules, subset = rhs %pin% "milk")
milk.rules <- subset(second.rules, subset = rhs %pin% "milk")
inspect(milk.rules)  # 41 rules
milk.rules <- subset(second.rules, subset = rhs %pin% "diary")
?Groceries
data(Groceries)
inspect(second.rules)
library(arules)
library(arulesViz)
library(datasets)
data("Groceries")
rules <- apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8))
options(digits=2)
inspect(rules[1:5])
rules<-sort(rules, by="confidence", decreasing=TRUE)
inspect(rules[1:5])
subset.matrix <- is.subset(rules, rules)
subset.matrix[lower.tri(subset.matrix, diag=T)] <- NA
redundant <- colSums(subset.matrix, na.rm=T) >= 1
rules.pruned <- rules[!redundant]
rules<-rules.pruned
inspect(rules[1:5])
options(digits=2)
inspect(rules[1:5])
library(arules)
library(arulesViz)
library(datasets)
data("Groceries")
rules <- apriori(Groceries, parameter = list(supp = 0.001, conf = 0.8))
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.08),
appearance = list(default="lhs",rhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.8,minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.8, minlen=3),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.8, minlen=4),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.8, minlen=5),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15, minlen=5),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15, minlen=3),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15, minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.2, minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.20, minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
rules<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15, minlen=2),
appearance = list(default="rhs",lhs="whole milk"),
control = list(verbose=F))
rules<-sort(rules, decreasing=TRUE,by="confidence")
inspect(rules[1:5])
library(neuralnet)
library(MASS)
factor_data <- read.csv("C:/Users/vino2/Google Drive/Semester 3/640 - Predictive/Project/Data_Mod.csv")
ln_returns <- vector();
for(i in 1:length(factor_data$ticker)){
if(identical(factor_data$ticker[i+1],factor_data$ticker[i])){
ln_returns[i] = log(factor_data$price[i+1]/factor_data$price[i]);
}else{
ln_returns[i] = -999;
}
}
ln_returns[1:20]
factor_data <- cbind(ln_returns,factor_data)
factor_data <- subset(factor_data,ln_returns != Inf & ln_returns != -Inf)
ln_returns <- NULL
ln_returns <- factor_data$ln_returns
data_header <- names(factor_data)
data_dates <- unique(factor_data$calendardate)
data_file_unique <- vector()
for(i in data_dates){
a <- paste("factor_data_", i, sep="");
assign(a, subset(factor_data, calendardate==i));
data_file_unique <- c(data_file_unique, a)
}
NA_data_file_unique <- vector()
for(j in data_file_unique){
a <- paste("NA_list_", j, sep="");
NA_data_file_unique <- c(NA_data_file_unique, a);
NA_list <- vector();
for(i in data_header){
z <- is.na(get(j)[[i]]);
if((sum(z)/length(get(j)[,1])) > .10){
NA_list <- c(NA_list, i)
}
}
assign(a, NA_list)
}
Na_unique_merge_list <- vector();
for(i in NA_data_file_unique){
Na_unique_merge_list <- c(Na_unique_merge_list, get(i))
}
Na_unique_merge_list <- unique(Na_unique_merge_list)
reduce_list <- vector("list", length = length(data_dates))
reduce_data_file_unique_date_data_list <- vector()
for(i in 1:length(data_file_unique)){
data_file_reduced <- get(data_file_unique[i])[-which(names(factor_data) %in% Na_unique_merge_list)]
reduce_list[[i]] <- data_file_reduced
}
row_bind=function(x,y){rbind(x,y)}
reduce_file <- Reduce(row_bind, reduce_list)
reduce_file <- na.omit(reduce_file)
reduce_file <- reduce_file[,-5]
reduce_file <- reduce_file[,-3]
reduce_file <- reduce_file[,-4]
reduce_file <- reduce_file[,-4]
ticker_dates <- reduce_file[,1:3]
reduce_file <- reduce_file[,-(3:1)]
reduce_file <- apply(reduce_file, 2, scale)
reduce_file <- data.frame(reduce_file)
reduce_file <- cbind(ticker_dates, reduce_file)
l <- ls()
l <- l[l!="reduce_file"]
rm(list=l)
rm(l)
reduce_list_modified <- NULL
unique_tickers <- unique(reduce_file$ticker)
for(u in unique_tickers){
temp <- subset(reduce_file,ticker==u)
if(dim(temp)[1]==20){
reduce_list_modified <- rbind(reduce_list_modified,temp)
}
temp<-NULL
}
factors <- c('calendardate','revenue','cor','rnd','ebit','netinc','epsdil','ncfo','ncfi','capex',
'ncfdiv','intangibles','debt','de','pe','pb','fcfps','assets','netmargin','marketcap','dps','ln_returns')
reduce_file_original <- reduce_file
reduce_file <- reduce_list_modified
reduce_list_modified <- NULL
unique_dates <- unique(reduce_file$calendardate)
unique_dates_train <- unique_dates[1:15]
unique_dates_test <- unique_dates[16:20]
reduce_file_data <- vector()
for(i in factors){
reduce_file_data <- cbind(reduce_file_data,reduce_file[,i])
}
reduce_file_data <- data.frame(reduce_file_data)
reduce_file_data <- cbind(reduce_file[,'ticker'],reduce_file_data)
colnames(reduce_file_data) <- c('ticker',factors)
coefficients_dates <- vector()
for(j in unique_dates_train){
temp <- subset(reduce_file_data,calendardate==j)
temp[c('calendardate','ticker')] <- list(NULL)
model <- lm(ln_returns ~ . , temp)
browser()
coefficients_dates <- rbind(coefficients_dates,model$coefficients)
temp <- NULL
model <- NULL
}
coefficients_dates <- cbind(unique_dates_train,coefficients_dates)
tickers <- read.csv("C:/Users/vino2/Google Drive/Semester 3/640 - Predictive/Project/companylist.csv",header = TRUE)
t_tickers <- intersect(tickers$Symbol,reduce_file$ticker)
reduce_file_tickers_data <- vector()
for(i in t_tickers){
reduce_file_tickers_data <- rbind(reduce_file_tickers_data,reduce_file_data[reduce_file_data$ticker==i,])
}
n_factors <- c('revenue','cor','rnd','ebit','netinc','epsdil','ncfo','ncfi','capex','ncfdiv',
'intangibles','debt','de','pe','pb','fcfps','assets','netmargin','marketcap','dps')
n_factors <- paste(n_factors, collapse = "+")
formula_ <- as.formula(paste("ln_returns~", n_factors, collapse = "+"))
coef_pred <- vector()
MSE <- vector()
temp <- NULL
unique_dates_train
temp <- subset(reduce_file_tickers_data,calendardate==20110331)
temp[c('calendardate','ticker')] <- list(NULL)
View(temp)
model <- neuralnet(formula = formula_, temp, hidden = c(10, 5))
pred <- compute(model, temp[,1:20])
coef_pred <- cbind(coef_pred, pred$net.result)
coef_pred
unique_dates
unique_dates_train
View(coef_pred)
pred$neurons
model$weights
plot(model)
coefficients_tickers_train <- vector()
temp <- NULL
for(j in unique_dates_train){
temp <- subset(reduce_file_tickers_data,calendardate==j)
temp[c('calendardate','ticker')] <- list(NULL)
model <- lm(ln_returns ~ . , temp)
#print(model$coefficients)
coefficients_tickers_train <- rbind(coefficients_tickers_train,model$coefficients)
temp <- NULL
model <- NULL
}
coefficients_tickers <- vector()
temp <- NULL
for(j in unique_dates){
temp <- subset(reduce_file_tickers_data,calendardate==j)
temp[c('calendardate','ticker')] <- list(NULL)
model <- lm(ln_returns ~ . , temp)
#print(model$coefficients)
coefficients_tickers <- rbind(coefficients_tickers,model$coefficients)
temp <- NULL
model <- NULL
}
View(coefficients_tickers)
temp <- NULL
coef_pred <- vector()
temp <- subset(reduce_file_tickers_data,calendardate==20110331)
temp[c('calendardate','ticker')] <- list(NULL)
model <- neuralnet(formula = formula_, temp, hidden = c(10, 5))
model$generalized.weights
model$startweights
model$net.result
unique_dates_train
model$weights
View(model$weights)
temp <- NULL
coef_pred <- vector()
temp <- subset(reduce_file_tickers_data,calendardate==20110331)
temp[c('calendardate','ticker')] <- list(NULL)
model <- neuralnet(formula = formula_, temp, hidden = c(10, 5))
pred <- compute(model, temp[,1:20])
coef_pred <- cbind(coef_pred, pred$net.result)
pred$neurons
View(pred$neurons)
summary(model)
summary(model$weights)
coef_pred <- vector()
MSE <- vector()
temp <- NULL
temp <- subset(reduce_file_tickers_data,calendardate==20110331)
temp[c('calendardate','ticker')] <- list(NULL)
library("nnet", lib.loc="C:/Program Files/R/R-3.3.3/library")
model <- nnet(formula = formula_, temp, hidden = c(10, 5))
model$weights
model$net.result
df <- read.csv("C:/Users/vino2/Google Drive/Semester 3/680 - Marketing Analytic/Final/case1.csv")
View(df)
View(df)
setwd("C:/Users/vino2/Google Drive/Udemy/Machine Learning A-Z/Part 2 - Regression/Section 4 - Simple Linear Regression")
dataset = read.csv('Salary_Data.csv')
View(dataset)
# Simple Linear Regresson
# Importing Dataset
dataset = read.csv('Salary_Data.csv')
# Splitting the dataset into training and testing data
library(caTools)
set.seed(123)
split = sample.split(dataset$Salary, SplitRation = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
split = sample.split(dataset$Salary, SplitRatio = 2/3)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
regressor = lm(formula = Salary ~ YearsExperience,
data = training_set)
summary(regressor)
y_pred = predict(regressor, newdata = test_set)
ypred
y_pred
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Salary') +
ylab('Years of Experience')
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Salary') +
ylab('Years of Experience')
ggplot() +
geom_point(aes(x = training_set$YearsExperience, y = training_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Training set)') +
xlab('Years of Experience') +
ylab('Salary')
ggplot() +
geom_point(aes(x = test_set$YearsExperience, y = test_set$Salary),
colour = 'red') +
geom_line(aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('Salary vs Experience (Test set)') +
xlab('Years of Experience') +
ylab('Salary')
